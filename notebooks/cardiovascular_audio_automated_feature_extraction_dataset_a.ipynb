{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Heartbeat Sound Classification with Visual Domain Deep Neural Networks - Dataset A of Pascal heart sound classification challange</h1>\n",
    "\n",
    "Setting up libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqphPlnpdaGu",
    "outputId": "00df6f18-4f1a-45ec-b8be-0fa2637dbdc7"
   },
   "outputs": [],
   "source": [
    "!pip install pydub\n",
    "!pip install --upgrade scikit-image\n",
    "!pip install librosa --user\n",
    "!pip install opencv-python\n",
    "!apt-get install libsndfile1-dev -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import neccesory libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onkwRu7zdtnW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from scipy.signal import butter,filtfilt\n",
    "import os,shutil\n",
    "import seaborn as sns\n",
    "from pydub import AudioSegment\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KmHiy5Rdy8p"
   },
   "outputs": [],
   "source": [
    "base_location=\"Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating neccesory folders, Add the file inside Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wusSocv7d4I1"
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"Data/set_a/spectograms/train_data\"\n",
    "!mkdir -p \"Data/set_a/spectograms/test_data\"\n",
    "!mkdir -p \"Data/set_a/split\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "tWgL-LsEd9E5",
    "outputId": "fac4fd33-4ec3-4e79-852a-d6d0733ffc33"
   },
   "outputs": [],
   "source": [
    "setA=pd.read_csv(\"{0}/set_a.csv\".format(base_location))\n",
    "labelled_setA=setA[setA[\"label\"].notnull()]\n",
    "## removing the sublabel as thats not required for this study\n",
    "labelled_setA=labelled_setA[[\"dataset\",\"fname\",\"label\"]]\n",
    "sns.set(rc={'figure.figsize':(14,5)})\n",
    "ax = sns.countplot(x ='label', data = labelled_setA)\n",
    "ax.set(xlabel='Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Functions - Lowpass filter, includes down-sampling and denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsphIFvgeAgd"
   },
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(audio_location, cutoff, order):\n",
    "    wav=get_wav(audio_location)\n",
    "    x,sr = librosa.load(audio_location,sr=wav.getframerate(),duration=(wav.getnframes()/wav.getframerate()))\n",
    "    x = librosa.resample(x, sr, sr/10)\n",
    "    sr=sr/10\n",
    "    \n",
    "    nyq = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Functions - get the audio duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gGJX43XeGiS"
   },
   "outputs": [],
   "source": [
    "def get_wav(audio_location):\n",
    "    wav = wave.open(audio_location)\n",
    "    return wav\n",
    "\n",
    "def get_audio_duration(audio_location):\n",
    "    wav = get_wav(audio_location)\n",
    "    return (wav.getnframes()/wav.getframerate())\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice each audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSDnG_xLeJKW"
   },
   "outputs": [],
   "source": [
    "def get_audio_slice(start_time,end_time,audio_location,part):\n",
    "    start_ms=start_time*1000\n",
    "    end_ms=end_time*1000\n",
    "    newAudio = AudioSegment.from_wav(audio_location)\n",
    "    newAudio = newAudio[start_ms:end_ms]\n",
    "    current_file_loc=os.path.split(audio_location)\n",
    "    exported_file_loc=\"{0}/split/part_{1}_{2}\".format(current_file_loc[0],part,current_file_loc[1])\n",
    "    newAudio.export(exported_file_loc, format=\"wav\")\n",
    "    print (\"Successfully splitted the {0} as part {1} from {2} to {3} seconds, split file available in {4}\".format(current_file_loc[1], part, start_time,end_time, exported_file_loc))\n",
    "    return exported_file_loc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split audio files with a length of 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAjemegreLVs"
   },
   "outputs": [],
   "source": [
    "def split_files(audio_location):\n",
    "    part_factor=3\n",
    "    tot_duration=get_audio_duration(audio_location) \n",
    "    parts=int(tot_duration/part_factor)\n",
    "    part_file_list=[]\n",
    "    for part in range(parts):\n",
    "        start_time=part*part_factor\n",
    "        end_time=start_time+part_factor\n",
    "        #print (\"Start time of part {0} is {1} and end time is {2} \".format(part,start_time,end_time))  \n",
    "        file_loc=get_audio_slice(start_time,end_time,audio_location,part)\n",
    "        part_file_list.append(file_loc)\n",
    "\n",
    "    return part_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleansing the filenames and loading into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33PnsR3LeSyU"
   },
   "outputs": [],
   "source": [
    "labelled_setA=setA[setA[\"label\"].notnull()]\n",
    "labelled_setA=labelled_setA[[\"dataset\",\"fname\",\"label\"]]\n",
    "\n",
    "\n",
    "labelled_setA['duration'] = labelled_setA['fname'].map(lambda x: get_audio_duration(\"{0}/{1}\".format(base_location,x) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting all files of dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASrAZKPMeZqe",
    "outputId": "cb524fe0-305c-49e3-c808-42f7bf657ab1"
   },
   "outputs": [],
   "source": [
    "labelled_setA['split_files']=labelled_setA['fname'].map(lambda x: split_files(\"{0}/{1}\".format(base_location,x) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the base dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmHeonepeZgJ",
    "outputId": "d3f0f669-f301-4ad2-d81d-f8ada5fb2488"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "flatdata = pd.DataFrame([( index, value) for ( index, values)\n",
    "                         in labelled_setA[ 'split_files' ].iteritems() for value in values],\n",
    "                             columns = [ 'index', 'split_files']).set_index( 'index' )\n",
    "  \n",
    "flattened_labelled_setA = labelled_setA.drop( 'split_files', axis = 1 ).join( flatdata )\n",
    "#display(flattened_labelled_setB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the flattened dataframe - This will show the data distribution of split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "KBad_va0eZPh",
    "outputId": "5a185c80-2c6a-4378-8ac9-909abc3cc08c"
   },
   "outputs": [],
   "source": [
    "## Removing files less than 3 seconds from the index\n",
    "flattened_labelled_setA=flattened_labelled_setA[flattened_labelled_setA['split_files'].notnull()]\n",
    "sns.set(rc={'figure.figsize':(14,5)})\n",
    "ax = sns.countplot(x ='label', data = flattened_labelled_setA, palette=[\"#3a76ab\", \"#ab594f\",\"#d19421\",\"green\"])\n",
    "\n",
    "count = flattened_labelled_setA.groupby(['label'])['fname'].count().values\n",
    "\n",
    "pos = range(len(count))\n",
    "\n",
    "\n",
    "for tick in pos:\n",
    "  ax.text(pos[tick],count[tick]+5, count[tick], horizontalalignment='center', size='small', color='black', weight='regular')\n",
    "#ax.set(xlabel='Label')\n",
    "ax.set(ylabel='Count')\n",
    "ax.set(title=\"Dataset A\")\n",
    "ax.set(xlabel='Cardiovascular sound category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the existing dataframe for IID considerations and balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "flattened_labelled_setA = shuffle(flattened_labelled_setA)\n",
    "artifact_data=flattened_labelled_setA[flattened_labelled_setA[\"label\"]=='artifact'].sample(70)\n",
    "flattened_labelled_setA=flattened_labelled_setA[flattened_labelled_setA[\"label\"]!='artifact']\n",
    "flattened_labelled_setA=pd.concat([flattened_labelled_setA,artifact_data], ignore_index=True)\n",
    "flattened_labelled_setA = shuffle(flattened_labelled_setA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the flattened dataframe - This will show the data distribution of split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Removing files less than 3 seconds from the index\n",
    "flattened_labelled_setA=flattened_labelled_setA[flattened_labelled_setA['split_files'].notnull()]\n",
    "sns.set(rc={'figure.figsize':(14,5)})\n",
    "ax = sns.countplot(x ='label', data = flattened_labelled_setA)\n",
    "ax.set(xlabel='Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the denoising cutoff and denoising the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff=192 #Hz\n",
    "order=1\n",
    "#butter_lowpass_filter(str(x),cutoff,order)\n",
    "flattened_labelled_setA[\"denoised_signal\"]=flattened_labelled_setA['split_files'].map(lambda x: butter_lowpass_filter(str(x),cutoff,order) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of pitch_shift and time_shift audio augmentation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(data,sr,num_steps):\n",
    "    return librosa.effects.pitch_shift(data,sr=4410,n_steps=-1)\n",
    "\n",
    "def time_shift (data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'left':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        #if direction == 1:\n",
    "            #shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data\n",
    "\n",
    "def audio_augment_data(data,label,type,sample_rate,aug_value,time_shift_direction,augment_size):\n",
    "    augmented=data[(data['label']==label) & (data['sample_type'] =='orig')]\n",
    "    if augment_size is not None:\n",
    "        augmented = augmented.sample(n=augment_size)\n",
    "    if type == \"time_shift\":\n",
    "        augmented['pitch_shift_augmented']=augmented['denoised_signal'].map(lambda x: time_shift(x,sample_rate,aug_value,time_shift_direction))\n",
    "        augmented[\"sample_type\"]=\"time_shift_augmented\"    \n",
    "    elif type == \"pitch_shift\":\n",
    "        augmented['pitch_shift_augmented']=augmented['denoised_signal'].map(lambda x: pitch_shift(x,sample_rate,aug_value))\n",
    "        augmented[\"sample_type\"]=\"pitch_shift_augmented\"\n",
    "\n",
    "    augmented=augmented.drop(['denoised_signal'], axis = 1)\n",
    "    augmented.rename(columns={'pitch_shift_augmented':'denoised_signal'}, inplace=True)\n",
    "    data=pd.concat([data, augmented])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFwEVRhUgIG9"
   },
   "outputs": [],
   "source": [
    "flattened_labelled_setA.to_csv(\"Data/set_a/denoise_split_master.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly shuffling the denoised audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7f7HWc7gJHX"
   },
   "outputs": [],
   "source": [
    "flattened_labelled_setA=shuffle(flattened_labelled_setA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train and test data, and visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "PpEtkqkFjgTY",
    "outputId": "f532ecc7-089c-4abd-be41-11001d910283"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(flattened_labelled_setA, test_size=0.3)\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "## Removing files less than 3 seconds from the index\n",
    "fig, ax = plt.subplots(1,2, sharey=True,figsize=(15, 5))\n",
    "#sns.set(rc={'figure.figsize':(14,5)})\n",
    "ax_1 = sns.countplot(x ='label', data = train,ax=ax[0])\n",
    "ax_1.set(xlabel='TRAIN')\n",
    "ax_2 = sns.countplot(x ='label', data = test,ax=ax[1])\n",
    "ax_2.set(xlabel='TEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting only training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sample_type\"]=\"orig\"\n",
    "train=audio_augment_data(train,'extrahls','pitch_shift',4410,-1,None,None)\n",
    "train=audio_augment_data(train,'normal','pitch_shift',4410,-1,None,None)\n",
    "train=audio_augment_data(train,'murmur','pitch_shift',4410,-1,None,None)\n",
    "train=audio_augment_data(train,'artifact','pitch_shift',4410,-1,None,None)\n",
    "\n",
    "\n",
    "train=audio_augment_data(train,'extrahls','time_shift',4000,1,'right',None)\n",
    "train=audio_augment_data(train,'normal','time_shift',4000,1,'right',None)\n",
    "train=audio_augment_data(train,'murmur','time_shift',4000,1,'right',None)\n",
    "train=audio_augment_data(train,'artifact','time_shift',4000,1,'right',None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, sharey=True,figsize=(15, 5))\n",
    "ax_1 = sns.countplot(x ='label', data = train)\n",
    "ax_1.set(xlabel='TRAIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of specAugment - reference https://github.com/KimJeongSun/SpecAugment_numpy_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QshIXvyJjj-3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as nl\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import dct,idct\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "def plot_spec(spec,out):\n",
    "    librosa.display.specshow(spec, fmax=8000)\n",
    "    plt.savefig(out)\n",
    "    plt.cla()\n",
    "\n",
    "\n",
    "def makeT(cp):\n",
    "    # cp: [K x 2] control points\n",
    "    # T: [(K+3) x (K+3)]\n",
    "    K = cp.shape[0]\n",
    "    T = np.zeros((K+3, K+3))\n",
    "    T[:K, 0] = 1\n",
    "    T[:K, 1:3] = cp\n",
    "    T[K, 3:] = 1\n",
    "    T[K+1:, 3:] = cp.T\n",
    "    R = squareform(pdist(cp, metric='euclidean'))\n",
    "    R = R * R\n",
    "    R[R == 0] = 1 # a trick to make R ln(R) 0\n",
    "    R = R * np.log(R)\n",
    "    np.fill_diagonal(R, 0)\n",
    "    T[:K, 3:] = R\n",
    "    return T\n",
    "\n",
    "def liftPts(p, cp):\n",
    "    # p: [N x 2], input points\n",
    "    # cp: [K x 2], control points\n",
    "    # pLift: [N x (3+K)], lifted input points\n",
    "    N, K = p.shape[0], cp.shape[0]\n",
    "    pLift = np.zeros((N, K+3))\n",
    "    pLift[:,0] = 1\n",
    "    pLift[:,1:3] = p\n",
    "    R = cdist(p, cp, 'euclidean')\n",
    "    R = R * R\n",
    "    R[R == 0] = 1\n",
    "    R = R * np.log(R)\n",
    "    pLift[:,3:] = R\n",
    "    return pLift\n",
    "    \n",
    "def specAug(audio,sampling_rate,num,out):\n",
    "    time_sum = 0\n",
    "\n",
    "    spec = librosa.feature.melspectrogram(y=audio,sr=sampling_rate,n_fft=200, hop_length=4)\n",
    "    \n",
    "    \n",
    "    spec = librosa.power_to_db(spec,ref=np.max)\n",
    "    \n",
    "    print(\"start to SpecAugment %d times\" % num)\n",
    "    for n in range(num): \n",
    "        start = time.time()\n",
    "        W=40\n",
    "        T=30\n",
    "        F=13\n",
    "        mt=2\n",
    "        mf=2\n",
    "\n",
    "        # Nframe : number of spectrum frame\n",
    "        Nframe = spec.shape[1]\n",
    "        # Nbin : number of spectrum freq bin\n",
    "        Nbin = spec.shape[0]\n",
    "        # check input length\n",
    "        if Nframe < W*2+1:\n",
    "            W = int(Nframe/4)\n",
    "        if Nframe < T*2+1:\n",
    "            T = int(Nframe/mt)\n",
    "        if Nbin < F*2+1:\n",
    "            F = int(Nbin/mf)\n",
    "\n",
    "        # warping parameter initialize\n",
    "        w = random.randint(-W,W)\n",
    "        center = random.randint(W,Nframe-W)\n",
    "\n",
    "        src = np.asarray([[ float(center),  1], [ float(center),  0], [ float(center),  2], [0, 0], [0, 1], [0, 2], [Nframe-1, 0], [Nframe-1, 1], [Nframe-1, 2]])\n",
    "        dst = np.asarray([[ float(center+w),  1], [ float(center+w),  0], [ float(center+w),  2], [0, 0], [0, 1], [0, 2], [Nframe-1, 0], [Nframe-1, 1], [Nframe-1, 2]])\n",
    "        #print(src,dst)\n",
    "\n",
    "        # source control points\n",
    "        xs, ys = src[:,0],src[:,1]\n",
    "        cps = np.vstack([xs, ys]).T\n",
    "        # target control points\n",
    "        xt, yt = dst[:,0],dst[:,1]\n",
    "        # construct TT\n",
    "        TT = makeT(cps)\n",
    "\n",
    "        # solve cx, cy (coefficients for x and y)\n",
    "        xtAug = np.concatenate([xt, np.zeros(3)])\n",
    "        ytAug = np.concatenate([yt, np.zeros(3)])\n",
    "        cx = nl.solve(TT, xtAug) # [K+3]\n",
    "        cy = nl.solve(TT, ytAug)\n",
    "\n",
    "        # dense grid\n",
    "        x = np.linspace(0, Nframe-1,Nframe)\n",
    "        y = np.linspace(1,1,1)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "\n",
    "        xgs, ygs = x.flatten(), y.flatten()\n",
    "\n",
    "        gps = np.vstack([xgs, ygs]).T\n",
    "\n",
    "        # transform\n",
    "        pgLift = liftPts(gps, cps) # [N x (K+3)]\n",
    "        xgt = np.dot(pgLift, cx.T)     \n",
    "        spec_warped = np.zeros_like(spec)\n",
    "        for f_ind in range(Nbin):\n",
    "            spec_tmp = spec[f_ind,:]\n",
    "            func = interpolate.interp1d(xgt, spec_tmp,fill_value=\"extrapolate\")\n",
    "            xnew = np.linspace(0, Nframe-1,Nframe)\n",
    "            spec_warped[f_ind,:] = func(xnew)\n",
    "\n",
    "        # sample mt of time mask ranges\n",
    "        t = np.random.randint(T-1, size=mt)+1\n",
    "        # sample mf of freq mask ranges\n",
    "        f = np.random.randint(F-1, size=mf)+1\n",
    "        # mask_t : time mask vector\n",
    "        mask_t = np.ones((Nframe,1))\n",
    "        ind = 0\n",
    "        t_tmp = t.sum() + mt\n",
    "        for _t in t:\n",
    "            k = random.randint(ind,Nframe-t_tmp)\n",
    "            mask_t[k:k+_t] = 0\n",
    "            ind = k+_t+1\n",
    "            t_tmp = t_tmp - (_t+1)\n",
    "        mask_t[ind:] = 1\n",
    "\n",
    "        # mask_f : freq mask vector\n",
    "        mask_f = np.ones((Nbin,1))\n",
    "        ind = 0\n",
    "        f_tmp = f.sum() + mf\n",
    "        for _f in f:\n",
    "            k = random.randint(ind,Nbin-f_tmp)\n",
    "            mask_f[k:k+_f] = 0\n",
    "            ind = k+_f+1\n",
    "            f_tmp = f_tmp - (_f+1)\n",
    "        mask_f[ind:] = 1\n",
    "\n",
    "        # calculate mean\n",
    "        mean = np.mean(spec_warped)\n",
    "\n",
    "        # make spectrum to zero mean\n",
    "        spec_zero = spec_warped-mean\n",
    "\n",
    "        spec_masked = ((spec_zero * mask_t.T) * mask_f) + mean\n",
    "    #     spec_masked = ((spec_zero * mask_t).T * mask_f).T\n",
    "\n",
    "        end = time.time()\n",
    "        time_sum += (end - start)  \n",
    "        if n == 0:\n",
    "          plot_spec(spec,\"{0}_orginal.png\".format(out))\n",
    "          plot_spec(spec_warped,\"{0}_wrapped.png\".format(out))\n",
    "        plot_spec(spec_masked,\"{0}_masked_{1}.png\".format(out,n))\n",
    "    print(\"whole processing time : %.4f second\" % (time_sum))   \n",
    "    print(\"average processing time : %.2f ms\" % (time_sum*1000/num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Spectrogram and Augment with timewrapped and frequency masked Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WOZ1ADgjsPD"
   },
   "outputs": [],
   "source": [
    "def augment_spectrograms(audio,sr,filename,aug_num,step,sample_type):\n",
    "  file_list=[]\n",
    "  filename=filename.replace(\"split\",\"spectograms/{0}_data\".format(step))\n",
    "  if step =='train':    \n",
    "      filename=filename.replace(\".wav\",\"_{0}\".format(sample_type))\n",
    "      #filename=filename.replace(\".wav\",\"\")  \n",
    "  else:\n",
    "      filename=filename.replace(\".wav\",\"\")\n",
    "    \n",
    "  specAug(audio,sr,aug_num,filename)\n",
    "  file_list.append(\"{0}_orginal.png\".format(filename))\n",
    "  if step =='train':\n",
    "    file_list.append(\"{0}_wrapped.png\".format(filename))\n",
    "    for n in range (aug_num):\n",
    "        file_list.append(\"{0}_masked_{1}.png\".format(filename,n))   \n",
    "  return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating training spectogram images along with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sWsFEspXkBUV",
    "outputId": "3f717989-9c88-473d-ba10-aa33cc355f0b"
   },
   "outputs": [],
   "source": [
    "sr=4410\n",
    "data=list((map(lambda x,y,z: augment_spectrograms(x,sr,y,2,'train',z),train['denoised_signal'],train['split_files'],train['sample_type'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating only the test spectograms (without augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y2WD5yC5kJK9",
    "outputId": "a001e92a-b0e8-4c55-dc1f-0709fa8ee7e1"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data=list((map(lambda x,y: augment_spectrograms(x,sr,y,1,'test',None),test['denoised_signal'],test['split_files'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding file path information into existing pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z54Fk-tLmMFM"
   },
   "outputs": [],
   "source": [
    "train=train.assign(augmented_files = data)\n",
    "test=test.assign(augmented_files = test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening both train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ6uvOA4wFdP"
   },
   "outputs": [],
   "source": [
    "flat_aug_data = pd.DataFrame([( index, value) for ( index, values)\n",
    "                         in train[ 'augmented_files' ].iteritems() for value in values],\n",
    "                             columns = [ 'index', 'augmented_files']).set_index( 'index' )\n",
    "  \n",
    "train_aug = train.drop( 'augmented_files', axis = 1 ).join( flat_aug_data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "notuaVYbwMIO"
   },
   "outputs": [],
   "source": [
    "flat_aug_data = pd.DataFrame([( index, value) for ( index, values)\n",
    "                         in test[ 'augmented_files' ].iteritems() for value in values],\n",
    "                             columns = [ 'index', 'augmented_files']).set_index( 'index' )\n",
    "  \n",
    "test_aug = test.drop( 'augmented_files', axis = 1 ).join( flat_aug_data )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the train and test file location and label information. Also visualzing the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "lvZ3daM-wWo3",
    "outputId": "b20b26c7-de64-44fe-b51d-fb39e680a2f9"
   },
   "outputs": [],
   "source": [
    "train_aug_file_label=train_aug[[\"augmented_files\",\"label\"]].drop_duplicates()\n",
    "train_aug_file_label.to_csv(\"set_a_train_file_to_label_audio_aug.csv\")\n",
    "ax_1 = sns.countplot(x ='label', data = train_aug_file_label)\n",
    "ax_1.set(xlabel='TRAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "tSkOKqPzwkni",
    "outputId": "92bd45e1-819e-47af-fb08-8a244edfcafd"
   },
   "outputs": [],
   "source": [
    "test_aug_file_label=test_aug[[\"augmented_files\",\"label\"]]\n",
    "test_aug_file_label.to_csv(\"set_a_test_file_to_label_v1_audio_aug.csv\")\n",
    "ax_1 = sns.countplot(x ='label', data = test_aug_file_label)\n",
    "ax_1.set(xlabel='TEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "D9VpNRrQw5Y1",
    "outputId": "dcd91c3c-0885-4c5c-c65b-831da9c8015a"
   },
   "source": [
    "Plot images function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvcUFAxIxA-W"
   },
   "outputs": [],
   "source": [
    "# function to plot n images using subplots\n",
    "import cv2 as cv\n",
    "from skimage.transform import rescale, resize\n",
    "from matplotlib import pyplot as plt\n",
    "        \n",
    "def plot_image(images, captions=None, cmap=None ):\n",
    "    f, axes = plt.subplots(1, len(images), sharey=True)\n",
    "    f.set_figwidth(15)\n",
    "    for ax,image in zip(axes,images):\n",
    "        ax.imshow(image, cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7m6aPYofyoWd"
   },
   "outputs": [],
   "source": [
    "def image_scale(imagePath, image_height, image_width):\n",
    "    image = cv.imread(imagePath)\n",
    "    image = cv.resize(image, (image_height, image_width))                    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing spectrograms into 128*128 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwk1eeaWyrKC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_mapping=pd.read_csv(\"set_a_train_file_to_label_audio_aug.csv\")\n",
    "data_mapping[\"image\"]=data_mapping['augmented_files'].map(lambda x : image_scale(x,128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling dataset and Normalzing pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8J03GRVuy2MT"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "data_mapping=shuffle(data_mapping)\n",
    "data=np.array(list(data_mapping[\"image\"]), dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding labals as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDENMZXDy9IZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "le = LabelEncoder()\n",
    "labels=list(data_mapping[\"label\"])\n",
    "\n",
    "train_label = le.fit_transform(labels)\n",
    "labels = to_categorical(train_label,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting each category for weight calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMBEO32LzCRt",
    "outputId": "96bafea9-5a57-4284-9cc4-86fa103be8de"
   },
   "outputs": [],
   "source": [
    "extrahls=len(list(filter(lambda x : x==1 , train_label)))\n",
    "murmur= len(list(filter(lambda x : x==2 , train_label)))\n",
    "normal= len(list(filter(lambda x : x==3 , train_label)))\n",
    "artifact=len(list(filter(lambda x : x==0 , train_label)))\n",
    "extrahls+normal+murmur+artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training vs Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyldezfDzHvq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iNzSJ23zNXV"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator()\n",
    "val_aug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading test data for evaluation and pre-prprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itjRHP7nzcpY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from scipy.signal import butter,filtfilt\n",
    "import os,shutil\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cutoff=192 #Hz\n",
    "order=1\n",
    "import pandas as pd\n",
    "test_data_mapping=pd.read_csv(\"\"\"set_a_test_file_to_label_v1_audio_aug.csv\"\"\")\n",
    "test_data_mapping[\"image\"]=test_data_mapping['augmented_files'].map(lambda x : image_scale(x,128,128))\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "test_data_mapping=shuffle(test_data_mapping)\n",
    "test_data=np.array(list(test_data_mapping[\"image\"]), dtype=\"float\") / 255.0\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "test_labels=list(test_data_mapping[\"label\"])\n",
    "\n",
    "test_labels = le.transform(test_labels)\n",
    "test_labels = to_categorical(test_labels,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required callbacks, Model checkpoint and Reduce learning on Plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback(model_type, reduce_plateau_factor, patience_val,save_best_only):\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "    model_name = 'set_a_models_aug/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "         os.mkdir(model_name)\n",
    "        \n",
    "    filepath = model_name + model_type+ '-model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=save_best_only, save_weights_only=False, mode='auto', period=1)\n",
    "    #mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=reduce_plateau_factor, patience=patience_val, verbose = 1)\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrBZMicUTCIO",
    "outputId": "1341d798-3fd9-469f-bb3f-a3693dbab0ef"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16, MobileNet,ResNet50\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "\n",
    "lr=0.001; momentum_val=0.9;\n",
    "EPOCHS=20\n",
    "BS=8\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "#opt = SGD(lr=lr, momentum=0.9, decay=lr / EPOCHS)\n",
    "opt = Adam(lr=lr, decay=lr / EPOCHS)\n",
    "\n",
    "pretrained_model = MobileNet (\n",
    "        include_top=False,\n",
    "        input_shape=(128,128,3),\n",
    "        weights='imagenet'\n",
    "     )\n",
    "pretrained_model.trainable = False\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "#print(\"Number of layers in the base model: \", len(pretrained_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "#fine_tune_at = 50\n",
    "#pretrained_model.trainable = True\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "#for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "#  layer.trainable =  False\n",
    "\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "\n",
    "validation_generator = val_aug.flow(testX, testY,batch_size=BS)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\")) # fully connected\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "weight_for_extrahls = (extrahls)/(train_label.size) \n",
    "weight_for_murmur = (murmur)/(train_label.size) \n",
    "weight_for_normal = (normal)/(train_label.size) \n",
    "weight_for_artifact = (artifact)/(train_label.size) \n",
    "\n",
    "class_weight = {0:weight_for_artifact, 1:weight_for_extrahls, 2: weight_for_murmur, 3: weight_for_normal}\n",
    "\n",
    "\n",
    "model_type=\"MobileNet\" ; reduce_plateau_factor=0.2; patience_val=5\n",
    "callbacks_list = create_callback(model_type, reduce_plateau_factor, patience_val, save_best_only = True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
    "                        validation_data=(testX, testY),class_weight=class_weight,callbacks=callbacks_list,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAVMRUCx4muv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"set_a_models_aug/MobileNet-model-00012-0.00120-1.00000-0.23949-0.93651.h5\")\n",
    "\n",
    "\n",
    "score, acc,precision,recall,auc = model.evaluate(test_data, test_labels, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16, MobileNet,ResNet50,InceptionResNetV2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping \n",
    "\n",
    "lr=0.01; momentum_val=0.9;\n",
    "EPOCHS=15\n",
    "BS=5\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=lr, momentum=0.9, decay=lr / EPOCHS)\n",
    "#opt = Adam(lr=lr, decay=lr / EPOCHS)\n",
    "pretrained_model = InceptionResNetV2 (\n",
    "        include_top=False,\n",
    "        input_shape=(128,128,3),\n",
    "        weights='imagenet'\n",
    "     )\n",
    "\n",
    "\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "\n",
    "validation_generator = val_aug.flow(testX, testY,batch_size=BS)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\")) # fully connected\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "weight_for_extrahls = (extrahls)/(train_label.size) \n",
    "weight_for_murmur = (murmur)/(train_label.size) \n",
    "weight_for_normal = (normal)/(train_label.size) \n",
    "weight_for_artifact = (artifact)/(train_label.size) \n",
    "\n",
    "class_weight = {0:weight_for_artifact, 1:weight_for_extrahls, 2: weight_for_murmur, 3: weight_for_normal}\n",
    "\n",
    "\n",
    "model_type=\"InceptionResNetV2\" ; reduce_plateau_factor=0.2; patience_val=5\n",
    "callbacks_list = create_callback(model_type, reduce_plateau_factor, patience_val, save_best_only = True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
    "                        validation_data=(testX, testY),class_weight=class_weight,callbacks=callbacks_list,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"set_a_models_aug/InceptionResNetV2-model-00006-0.01927-0.97014-0.09625-0.95635.h5\")\n",
    "\n",
    "test_aug = ImageDataGenerator()\n",
    "\n",
    "\n",
    "score, acc,precision,recall,auc = model.evaluate(test_data, test_labels, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16, MobileNet,ResNet50,InceptionResNetV2,MobileNetV2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "#from keras.metrics import TruePositives\n",
    "#from tensorflow.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "\n",
    "lr=0.001; momentum_val=0.9;\n",
    "EPOCHS=40\n",
    "BS=8\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=lr, momentum=0.9, decay=lr / EPOCHS)\n",
    "#opt = Adam(lr=lr, decay=lr / EPOCHS)\n",
    "pretrained_model = MobileNetV2 (\n",
    "        include_top=False,\n",
    "        input_shape=(128,128,3),\n",
    "        weights='imagenet'\n",
    "     )\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "print(\"Number of layers in the base model: \", len(pretrained_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "#fine_tune_at = 140\n",
    "#pretrained_model.trainable = True\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "#for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "#  layer.trainable =  False\n",
    "\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "validation_generator = val_aug.flow(testX, testY,batch_size=BS)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\")) # fully connected\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "weight_for_extrahls = (extrahls)/(train_label.size) \n",
    "weight_for_murmur = (murmur)/(train_label.size) \n",
    "weight_for_normal = (normal)/(train_label.size) \n",
    "weight_for_artifact = (artifact)/(train_label.size) \n",
    "\n",
    "class_weight = {0:weight_for_artifact, 1:weight_for_extrahls, 2: weight_for_murmur, 3: weight_for_normal}\n",
    "\n",
    "\n",
    "model_type=\"MobileNetV2\" ; reduce_plateau_factor=0.2; patience_val=5\n",
    "callbacks_list = create_callback(model_type, reduce_plateau_factor, patience_val, save_best_only = True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
    "                        validation_data=(testX, testY),class_weight=class_weight,callbacks=callbacks_list,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"set_a_models_aug/MobileNetV2-model-00033-0.02748-0.96230-0.26808-0.91468.h5\")\n",
    "\n",
    "\n",
    "score, acc,precision,recall,auc = model.evaluate(test_data, test_labels, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(H.history['auc_13'])\n",
    "plt.plot(H.history['val_auc_13'])\n",
    "plt.title('Dataset A - Training History - MobileNetV2')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "\n",
    "lr=0.001; momentum_val=0.9;\n",
    "EPOCHS=40\n",
    "BS=8\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=lr, momentum=0.9, decay=lr / EPOCHS)\n",
    "#opt = Adam(lr=lr, decay=lr / EPOCHS)\n",
    "pretrained_model = ResNet152V2 (\n",
    "        include_top=False,\n",
    "        input_shape=(128,128,3),\n",
    "        weights='imagenet'\n",
    "     )\n",
    "pretrained_model.trainable = False\n",
    "#print(\"Number of layers in the base model: \", len(pretrained_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "#fine_tune_at = 500\n",
    "#pretrained_model.trainable = True\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "#for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "#  layer.trainable =  False\n",
    "\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "\n",
    "validation_generator = val_aug.flow(testX, testY,batch_size=BS)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation = \"relu\")) # fully connected\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "weight_for_extrahls = (extrahls)/(train_label.size) \n",
    "weight_for_murmur = (murmur)/(train_label.size) \n",
    "weight_for_normal = (normal)/(train_label.size) \n",
    "weight_for_artifact = (artifact)/(train_label.size) \n",
    "\n",
    "class_weight = {0:weight_for_artifact, 1:weight_for_extrahls, 2: weight_for_murmur, 3: weight_for_normal}\n",
    "\n",
    "\n",
    "model_type=\"ResNet152V2\" ; reduce_plateau_factor=0.2; patience_val=5\n",
    "callbacks_list = create_callback(model_type, reduce_plateau_factor, patience_val, save_best_only = True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
    "                        validation_data=(testX, testY),class_weight=class_weight,callbacks=callbacks_list,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "model = load_model(\"set_a_models_aug/ResNet152V2-model-00035-0.03293-0.95635-0.29911-0.88690.h5\")\n",
    "\n",
    "\n",
    "score, acc,precision,recall,auc = model.evaluate(test_data, test_labels, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(H.history['auc_4'])\n",
    "plt.plot(H.history['val_auc_4'])\n",
    "plt.title('Dataset A - Training History - ResNet152V2')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import Xception\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, Activation, Dropout,LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "\n",
    "lr=0.001; momentum_val=0.9;\n",
    "EPOCHS=15\n",
    "BS=8\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "#opt = SGD(lr=lr, momentum=0.9, decay=lr / EPOCHS)\n",
    "opt = Adam(lr=lr, decay=lr / EPOCHS)\n",
    "pretrained_model = Xception (\n",
    "        include_top=False,\n",
    "        input_shape=(128,128,3),\n",
    "        weights='imagenet'\n",
    "     )\n",
    "#pretrained_model.trainable = False\n",
    "\n",
    "\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "\n",
    "validation_generator = val_aug.flow(testX, testY,batch_size=BS)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\")) # fully connected\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "weight_for_extrahls = (extrahls)/(train_label.size) \n",
    "weight_for_murmur = (murmur)/(train_label.size) \n",
    "weight_for_normal = (normal)/(train_label.size) \n",
    "weight_for_artifact = (artifact)/(train_label.size) \n",
    "\n",
    "class_weight = {0:weight_for_artifact, 1:weight_for_extrahls, 2: weight_for_murmur, 3: weight_for_normal}\n",
    "\n",
    "\n",
    "model_type=\"Xception\" ; reduce_plateau_factor=0.2; patience_val=5\n",
    "callbacks_list = create_callback(model_type, reduce_plateau_factor, patience_val, save_best_only = True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
    "                        validation_data=(testX, testY),class_weight=class_weight,callbacks=callbacks_list,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data evaluation with Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"set_a_models_aug/Xception-model-00006-0.11832-0.82077-0.31194-0.88889.h5\")\n",
    "\n",
    "\n",
    "score, acc,precision,recall,auc = model.evaluate(test_data, test_labels, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import  Flatten, BatchNormalization, Activation, Dropout,LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "\n",
    "lr=0.001; momentum_val=0.9;\n",
    "EPOCHS=15\n",
    "BS=8\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "#opt = SGD(lr=lr, momentum=0.9, decay=lr / EPOCHS)\n",
    "opt = Adam(lr=lr, decay=lr / EPOCHS)\n",
    "pretrained_model = DenseNet169 (\n",
    "        include_top=False,\n",
    "        input_shape=(128,128,3),\n",
    "        weights='imagenet'\n",
    "     )\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "\n",
    "validation_generator = val_aug.flow(testX, testY,batch_size=BS)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\")) # fully connected\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "weight_for_extrahls = (extrahls)/(train_label.size) \n",
    "weight_for_murmur = (murmur)/(train_label.size) \n",
    "weight_for_normal = (normal)/(train_label.size) \n",
    "weight_for_artifact = (artifact)/(train_label.size) \n",
    "\n",
    "class_weight = {0:weight_for_artifact, 1:weight_for_extrahls, 2: weight_for_murmur, 3: weight_for_normal}\n",
    "\n",
    "\n",
    "model_type=\"DenseNet169\" ; reduce_plateau_factor=0.2; patience_val=5\n",
    "callbacks_list = create_callback(model_type, reduce_plateau_factor, patience_val, save_best_only = True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
    "                        validation_data=(testX, testY),class_weight=class_weight,callbacks=callbacks_list,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data evaluation with DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"set_a_models_aug/DenseNet169-model-00013-0.00150-1.00000-0.26483-0.91270.h5\")\n",
    "\n",
    "\n",
    "score, acc,precision,recall,auc = model.evaluate(test_data, test_labels, batch_size=8)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cardio_vascular_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
